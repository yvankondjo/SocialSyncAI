# Celery Architecture - SocialSync AI

**Date:** 2025-10-20
**Version:** 2.0 (Post-Migration)
**Status:** ‚úÖ Production

---

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Architecture Compl√®te](#architecture-compl√®te)
3. [Composants](#composants)
4. [Queues & Workers](#queues--workers)
5. [T√¢ches P√©riodiques (Beat)](#t√¢ches-p√©riodiques-beat)
6. [Flux de Donn√©es](#flux-de-donn√©es)
7. [Configuration](#configuration)
8. [Monitoring](#monitoring)

---

## Vue d'Ensemble

### Probl√®me R√©solu

**Avant Celery:**
- T√¢ches longues bloquent FastAPI (timeout webhooks)
- Si FastAPI crash ‚Üí t√¢ches perdues
- Pas de retry automatique
- Impossible de scaler

**Avec Celery:**
- ‚úÖ FastAPI r√©pond < 200ms (envoie t√¢che √† Redis)
- ‚úÖ Workers ex√©cutent en arri√®re-plan
- ‚úÖ Retry automatique configurable
- ‚úÖ Scalabilit√© horizontale (multiple workers)
- ‚úÖ T√¢ches p√©riodiques (Celery Beat)

### Architecture 3-Tiers

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  CELERY ARCHITECTURE                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üì± PRODUCTEURS (Envoient des t√¢ches)
‚îú‚îÄ FastAPI (webhooks, API calls)
‚îî‚îÄ Celery Beat (t√¢ches p√©riodiques)

üì¨ BROKER (File d'attente)
‚îî‚îÄ Redis (queues: ingest, scheduler, comments)

üë∑ CONSOMMATEURS (Ex√©cutent les t√¢ches)
‚îú‚îÄ Worker Ingest (DMs/chats)
‚îú‚îÄ Worker Scheduler (posts planifi√©s)
‚îî‚îÄ Worker Comments (commentaires)

‚è∞ SCHEDULER (Horloge distribu√©e)
‚îî‚îÄ Celery Beat (envoie t√¢ches p√©riodiques)

üìä MONITORING
‚îî‚îÄ Flower (dashboard web)
```

---

## Architecture Compl√®te

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      FASTAPI (API LAYER)                      ‚îÇ
‚îÇ  Webhooks, REST API, OAuth                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ Envoie t√¢ches                      ‚îÇ Envoie t√¢ches
             ‚îÇ                                    ‚îÇ
             ‚ñº                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CELERY BEAT     ‚îÇ                  ‚îÇ      REDIS       ‚îÇ
‚îÇ  (Scheduler)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    (Broker)      ‚îÇ
‚îÇ                  ‚îÇ  Envoie t√¢ches   ‚îÇ                  ‚îÇ
‚îÇ  Schedules:      ‚îÇ  p√©riodiques     ‚îÇ  Queues:         ‚îÇ
‚îÇ  - 0.5s: scan    ‚îÇ                  ‚îÇ  - ingest        ‚îÇ
‚îÇ  - 1min: posts   ‚îÇ                  ‚îÇ  - scheduler     ‚îÇ
‚îÇ  - 5min: comments‚îÇ                  ‚îÇ  - comments      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                 ‚îÇ
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ                  ‚îÇ                  ‚îÇ
                              ‚ñº                  ‚ñº                  ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Worker Ingest   ‚îÇ ‚îÇWorker Scheduler‚îÇ ‚îÇWorker Comments ‚îÇ
                    ‚îÇ Queue: ingest   ‚îÇ ‚îÇQueue: scheduler‚îÇ ‚îÇQueue: comments ‚îÇ
                    ‚îÇ                 ‚îÇ ‚îÇ                ‚îÇ ‚îÇ                ‚îÇ
                    ‚îÇ Traite:         ‚îÇ ‚îÇ Traite:        ‚îÇ ‚îÇ Traite:        ‚îÇ
                    ‚îÇ - DMs WhatsApp  ‚îÇ ‚îÇ - Posts planif.‚îÇ ‚îÇ - Polling      ‚îÇ
                    ‚îÇ - DMs Instagram ‚îÇ ‚îÇ - Publishing   ‚îÇ ‚îÇ - Processing   ‚îÇ
                    ‚îÇ - Documents     ‚îÇ ‚îÇ - Retry failed ‚îÇ ‚îÇ - AI responses ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                  ‚îÇ                  ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                 ‚ñº
                                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                      ‚îÇ   SUPABASE PG    ‚îÇ
                                      ‚îÇ  (Persistence)   ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Composants

### 1. Redis (Broker & Backend)

**R√¥le:** Messagerie ultra-rapide

**Utilisation:**
- **Broker:** File d'attente des t√¢ches
- **Result Backend:** Stockage des r√©sultats
- **Message Batching:** Batches DMs/chats (2s window)

**Configuration:**
```python
# backend/app/workers/celery_app.py
celery = Celery(
    "socialsyncAI",
    broker="redis://redis:6379/0",
    backend="redis://redis:6379/0",
)
```

**Cl√©s Redis:**
```redis
# Queues Celery
celery:ingest    ‚Üí [Task1, Task2, Task3]
celery:scheduler ‚Üí [Task4, Task5]
celery:comments  ‚Üí [Task6]

# R√©sultats
celery-task-result:abc-123 ‚Üí {"status": "SUCCESS", "result": {...}}

# Batching DMs (notre syst√®me)
conv:whatsapp:+33612345678:+33698765432:msgs ‚Üí [Msg1, Msg2]
conv:deadlines ‚Üí {conversation_id: timestamp}
```

---

### 2. Celery Worker

**R√¥le:** Ex√©cute les t√¢ches en arri√®re-plan

**Process Python qui:**
1. Se connecte √† Redis
2. √âcoute une ou plusieurs queues
3. Prend les t√¢ches d√®s qu'elles arrivent
4. Ex√©cute le code Python
5. Stocke le r√©sultat dans Redis

**Commande:**
```bash
celery -A app.workers.celery_app worker \
  -Q ingest \              # Queue √† √©couter
  -n ingest@%h \           # Nom du worker
  --autoscale=10,3 \       # Min 3, max 10 process
  -l info                  # Log level
```

**Scalabilit√©:**
```bash
# Multiple workers pour la m√™me queue
celery -A app.workers.celery_app worker -Q ingest -n worker1@%h
celery -A app.workers.celery_app worker -Q ingest -n worker2@%h
celery -A app.workers.celery_app worker -Q ingest -n worker3@%h

# Redis distribue automatiquement les t√¢ches
Queue: [Task1, Task2, Task3, Task4]
        ‚Üì      ‚Üì      ‚Üì      ‚Üì
     Worker1 Worker2 Worker3 Worker1
```

---

### 3. Celery Beat

**R√¥le:** Horloge distribu√©e (Cron job)

**Diff√©rence Worker vs Beat:**
| Celery Worker | Celery Beat |
|---------------|-------------|
| **Ex√©cute** les t√¢ches | **Planifie** les t√¢ches |
| √âcoute Redis | Envoie vers Redis |
| Peut y en avoir plusieurs | **UN SEUL** (master) |
| Obligatoire | Optionnel* |

*Optionnel sauf pour t√¢ches p√©riodiques

**Commande:**
```bash
celery -A app.workers.celery_app beat -l info
```

**‚ö†Ô∏è IMPORTANT: Un seul Beat par syst√®me !**

Plusieurs Beat = T√¢ches dupliqu√©es (danger)

---

### 4. Flower (Monitoring)

**R√¥le:** Dashboard web pour Celery

**Features:**
- üìä Workers actifs/inactifs
- üìà Graphiques de performance
- üìã Liste des t√¢ches (en cours, succ√®s, √©checs)
- ‚è±Ô∏è Temps d'ex√©cution moyen
- üîÑ Retry logs
- üìä Task routing

**Acc√®s:**
```bash
celery -A app.workers.celery_app flower --port=5555
# http://localhost:5555
```

---

## Queues & Workers

### Queue Ingest (DMs/Chats)

**Responsabilit√©:** Messages directs et documents

**T√¢ches:**
```python
# backend/app/workers/ingest.py

@celery.task(name="app.workers.ingest.scan_redis_batches")
def scan_redis_batches_task(self):
    """
    Scan Redis pour batches de messages dus (toutes les 0.5s)
    Appel√© par Celery Beat
    """
    batches = message_batcher.get_due_conversations()
    for batch in batches:
        process_batch(batch)

@celery.task(name="app.workers.ingest.process_document")
def process_document_task(self, document_id: str):
    """
    Parse et indexe un document dans la knowledge base
    Appel√© manuellement (FastAPI)
    """
    doc = download_document(document_id)
    chunks = split_text(doc)
    embed_and_store(chunks)
```

**Worker:**
```bash
celery -A app.workers.celery_app worker -Q ingest -n ingest@%h
```

---

### Queue Scheduler (Posts Planifi√©s)

**Responsabilit√©:** Publication de posts planifi√©s

**T√¢ches:**
```python
# backend/app/workers/scheduler.py

@celery.task(name="app.workers.scheduler.enqueue_due_posts")
def enqueue_due_posts():
    """
    Trouve les posts dont scheduled_at est pass√© (toutes les 1 min)
    Appel√© par Celery Beat
    """
    due_posts = get_due_posts()
    for post in due_posts:
        publish_post.delay(post.id)

@celery.task(
    bind=True,
    max_retries=3,
    default_retry_delay=300,  # 5 min
)
def publish_post(self, post_id: str):
    """
    Publie un post sur la plateforme (Instagram, Facebook, etc.)
    Appel√© par enqueue_due_posts
    """
    try:
        post = get_post(post_id)
        platform_api.publish(post)
        update_status(post_id, "published")
    except Exception as e:
        # Retry automatique
        raise self.retry(exc=e)
```

**Worker:**
```bash
celery -A app.workers.celery_app worker -Q scheduler -n scheduler@%h
```

---

### Queue Comments (Commentaires)

**Responsabilit√©:** Polling et traitement commentaires

**T√¢ches:**
```python
# backend/app/workers/comments.py

@celery.task(name="app.workers.comments.poll_post_comments")
def poll_post_comments():
    """
    Poll les commentaires de tous les posts monitor√©s (toutes les 5 min)
    Appel√© par Celery Beat
    """
    monitored_posts = get_monitored_posts()
    for post in monitored_posts:
        fetch_new_comments.delay(post.id)

@celery.task(
    bind=True,
    max_retries=3,
    default_retry_delay=300,
)
def fetch_new_comments(self, post_id: str):
    """
    Fetch nouveaux commentaires d'un post
    D√©clenche process_comment pour chaque nouveau commentaire
    """
    try:
        comments = platform_api.get_comments(post_id)
        for comment in comments:
            process_comment.delay(comment.id)
    except Exception as e:
        raise self.retry(exc=e)

@celery.task
def process_comment(comment_id: str):
    """
    Traite un commentaire (d√©tection, AI, r√©ponse)
    """
    comment = get_comment(comment_id)

    # D√©tection conversation (ignore @mentions, user-to-user)
    if is_conversation(comment):
        return

    # G√©n√®re r√©ponse AI (avec Vision AI)
    response = generate_ai_response(comment)

    # Envoie r√©ponse
    platform_api.reply(comment_id, response)
```

**Worker:**
```bash
celery -A app.workers.celery_app worker -Q comments -n comments@%h
```

---

## T√¢ches P√©riodiques (Beat)

### Configuration Schedule

**Fichier:** `backend/app/workers/celery_app.py`

```python
celery.conf.beat_schedule = {
    # DMs/Chats - Scan toutes les 0.5s
    "scan-redis-batches-every-500ms": {
        "task": "app.workers.ingest.scan_redis_batches",
        "schedule": 0.5,
        "options": {
            "expires": 0.4,  # Expire si pas ex√©cut√©e en 400ms
        }
    },

    # Posts Planifi√©s - Check toutes les 1 min
    "enqueue-due-posts-every-minute": {
        "task": "app.workers.scheduler.enqueue_due_posts",
        "schedule": 60.0,
        "options": {
            "expires": 55,
        }
    },

    # Commentaires - Poll toutes les 5 min
    "poll-post-comments-every-5-minutes": {
        "task": "app.workers.comments.poll_post_comments",
        "schedule": 300.0,
        "options": {
            "expires": 290,
        }
    },
}
```

### Timeline Beat

```
T=0s    ‚Üí Beat: Envoie scan_redis_batches ‚Üí Redis queue "ingest"
T=0s    ‚Üí Beat: Envoie enqueue_due_posts ‚Üí Redis queue "scheduler"
T=0s    ‚Üí Beat: Envoie poll_post_comments ‚Üí Redis queue "comments"

T=0.5s  ‚Üí Beat: Envoie scan_redis_batches ‚Üí Redis queue "ingest"
T=1s    ‚Üí Beat: Envoie scan_redis_batches ‚Üí Redis queue "ingest"
T=1.5s  ‚Üí Beat: Envoie scan_redis_batches ‚Üí Redis queue "ingest"

T=60s   ‚Üí Beat: Envoie enqueue_due_posts ‚Üí Redis queue "scheduler"
T=60.5s ‚Üí Beat: Envoie scan_redis_batches ‚Üí Redis queue "ingest"

T=300s  ‚Üí Beat: Envoie poll_post_comments ‚Üí Redis queue "comments"

... (boucle infinie)
```

---

## Flux de Donn√©es

### Flux 1: DM WhatsApp (T√¢che P√©riodique)

```
1. User envoie "Hello" via WhatsApp
   ‚Üì
2. Meta webhook ‚Üí FastAPI POST /api/whatsapp/webhook
   ‚Üì
3. FastAPI:
   - Sauvegarde message en BDD (100ms)
   - Ajoute √† Redis batch (10ms)
   - R√©pond "OK" √† Meta (< 200ms total) ‚úÖ
   ‚Üì
4. [2 secondes plus tard - Deadline atteinte]
   ‚Üì
5. Celery Beat (toutes les 0.5s):
   - Envoie task scan_redis_batches ‚Üí Redis queue "ingest"
   ‚Üì
6. Worker Ingest:
   - Prend task scan_redis_batches
   - Ex√©cute: batch_scanner._process_due_conversations()
   - Trouve le batch (deadline pass√©e)
   - Lock Redis (√©vite doublons)
   ‚Üì
7. Worker Ingest (suite):
   - R√©cup√®re messages du batch
   - Appel AI (10 secondes, pas grave)
   - G√©n√®re r√©ponse AI
   - Envoie via WhatsApp API
   - Sauvegarde r√©ponse en BDD
   ‚Üì
8. User re√ßoit r√©ponse AI ‚úÖ
```

**Timeline:**
```
0ms     ‚îÇ Webhook arrive
100ms   ‚îÇ Message saved in DB
110ms   ‚îÇ Added to Redis batch
200ms   ‚îÇ FastAPI responds "OK" ‚úÖ
        ‚îÇ
2000ms  ‚îÇ Batch deadline reached
2500ms  ‚îÇ Beat tick (next 0.5s scan)
2510ms  ‚îÇ Task sent to Redis
2550ms  ‚îÇ Worker picks task
2600ms  ‚îÇ Batch found, lock acquired
5000ms  ‚îÇ AI processing...
10000ms ‚îÇ AI response ready
10500ms ‚îÇ WhatsApp message sent ‚úÖ
```

---

### Flux 2: Post Planifi√© (T√¢che P√©riodique)

```
1. User schedule un post pour 14h00
   ‚Üì
2. FastAPI:
   - INSERT scheduled_posts (status=queued, scheduled_at=14h00)
   - R√©pond "OK"
   ‚Üì
3. [14h00 arrive]
   ‚Üì
4. Celery Beat (toutes les 1 min):
   - 13h59 ‚Üí enqueue_due_posts ‚Üí Pas encore
   - 14h00 ‚Üí enqueue_due_posts ‚Üí Post trouv√© !
   - Envoie task publish_post(post_id) ‚Üí Redis queue "scheduler"
   ‚Üì
5. Worker Scheduler:
   - Prend task publish_post
   - UPDATE status="publishing"
   - Appel Instagram API (3 secondes)
   - UPDATE status="published"
   ‚Üì
6. Post publi√© sur Instagram ‚úÖ

Si erreur:
   - Worker: raise self.retry(exc=e)
   - Celery: Attend 5 min (default_retry_delay)
   - Retry automatique (max 3 fois)
```

---

### Flux 3: Document Upload (T√¢che Manuelle)

```
1. User upload PDF dans knowledge base
   ‚Üì
2. FastAPI:
   - Upload fichier ‚Üí Supabase Storage
   - INSERT knowledge_documents (status=pending)
   - Envoie task process_document.delay(doc_id) ‚Üí Redis queue "ingest"
   - R√©pond "OK" (< 500ms)
   ‚Üì
3. Worker Ingest:
   - Prend task process_document
   - Download PDF (5s)
   - Parse texte (10s)
   - Split en chunks (2s)
   - Generate embeddings (30s)
   - INSERT knowledge_chunks (5s)
   - UPDATE status="indexed"
   ‚Üì
4. Document index√© ‚úÖ (52 secondes total, en arri√®re-plan)
```

---

## Configuration

### Celery App

**Fichier:** `backend/app/workers/celery_app.py`

```python
import os
from celery import Celery

celery = Celery(
    "socialsyncAI",
    broker=os.getenv("CELERY_BROKER_URL", "redis://redis:6379/0"),
    backend=os.getenv("CELERY_RESULT_BACKEND", "redis://redis:6379/0"),
)

celery.conf.update(
    # Routing des t√¢ches par queue
    task_routes={
        "app.workers.ingest.*": {"queue": "ingest"},
        "app.workers.scheduler.*": {"queue": "scheduler"},
        "app.workers.comments.*": {"queue": "comments"},
    },

    # Timeouts
    task_time_limit=1800,  # 30 min max/task (hard kill)
    task_soft_time_limit=1700,  # 28 min (SoftTimeLimitExceeded)

    # Worker lifecycle
    worker_max_tasks_per_child=200,  # Restart apr√®s 200 tasks (√©vite memory leaks)

    # Timezone
    timezone="UTC",
    enable_utc=True,

    # Result backend
    result_expires=3600,  # R√©sultats expir√©s apr√®s 1h (√©conomise Redis)
)

# Beat schedule (t√¢ches p√©riodiques)
celery.conf.beat_schedule = {
    "scan-redis-batches-every-500ms": {
        "task": "app.workers.ingest.scan_redis_batches",
        "schedule": 0.5,
    },
    "enqueue-due-posts-every-minute": {
        "task": "app.workers.scheduler.enqueue_due_posts",
        "schedule": 60.0,
    },
    "poll-post-comments-every-5-minutes": {
        "task": "app.workers.comments.poll_post_comments",
        "schedule": 300.0,
    },
}

# Import des modules workers (n√©cessaire pour d√©couverte des tasks)
from app.workers import ingest
from app.workers import scheduler
from app.workers import comments
```

### Variables d'Environnement

**Fichier:** `backend/.env`

```bash
# Redis
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# Flower (monitoring)
FLOWER_BASIC_AUTH=admin:password

# Supabase (pour workers)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY=xxx
SUPABASE_ANON_KEY=xxx

# Meta API (pour workers)
META_GRAPH_VERSION=v24.0
META_APP_SECRET=xxx
```

---

## Monitoring

### Commandes Celery

```bash
# Lister workers actifs
celery -A app.workers.celery_app inspect active_queues

# Stats d√©taill√©es
celery -A app.workers.celery_app inspect stats

# T√¢ches en cours
celery -A app.workers.celery_app inspect active

# Schedule Beat actif
celery -A app.workers.celery_app inspect scheduled

# Ping workers
celery -A app.workers.celery_app inspect ping

# Arr√™t propre
celery -A app.workers.celery_app control shutdown
```

### Flower Dashboard

```bash
# D√©marrer Flower
celery -A app.workers.celery_app flower --port=5555

# Acc√®s
http://localhost:5555
```

**Metrics disponibles:**
- Workers actifs/inactifs
- Queues (taille, d√©bit)
- Tasks (succ√®s, √©checs, retry)
- Graphiques temps r√©el
- Logs d√©taill√©s par task

### Redis Monitoring

```bash
# Connexion Redis
redis-cli

# Voir queues Celery
LLEN celery:ingest
LLEN celery:scheduler
LLEN celery:comments

# Voir r√©sultats
KEYS celery-task-result:*

# M√©moire utilis√©e
INFO memory

# Voir batches DMs
KEYS conv:*
ZRANGE conv:deadlines 0 -1 WITHSCORES
```

---

## Best Practices

### 1. Un Seul Beat

**‚ùå Jamais √ßa:**
```bash
# Terminal 1
celery -A app.workers.celery_app beat

# Terminal 2
celery -A app.workers.celery_app beat  # ‚ùå DANGER: T√¢ches dupliqu√©es !
```

**‚úÖ Toujours √ßa:**
```bash
# Beat en daemon (production)
celery -A app.workers.celery_app beat -d --pidfile=/var/run/celery/beat.pid

# V√©rifier qu'un seul tourne
ps aux | grep "celery.*beat" | wc -l  # Doit retourner: 1
```

### 2. Workers D√©di√©s par Queue

**‚ùå Pas optimal:**
```bash
# Un seul worker pour tout
celery -A app.workers.celery_app worker -Q ingest,scheduler,comments
```

**‚úÖ Optimal (scalabilit√©):**
```bash
# Workers sp√©cialis√©s
celery -A app.workers.celery_app worker -Q ingest -n ingest@%h --autoscale=10,3
celery -A app.workers.celery_app worker -Q scheduler -n scheduler@%h --autoscale=5,2
celery -A app.workers.celery_app worker -Q comments -n comments@%h --autoscale=3,1
```

### 3. Retry Strategy

```python
@celery.task(
    bind=True,
    max_retries=3,
    default_retry_delay=60,  # 1 min entre retries
    autoretry_for=(httpx.TimeoutException, redis.ConnectionError),
)
def my_task(self, ...):
    try:
        # Code
        pass
    except Exception as e:
        # Retry avec backoff exponentiel
        raise self.retry(exc=e, countdown=60 * (2 ** self.request.retries))
```

### 4. Idempotence

**Les t√¢ches doivent √™tre idempotentes** (m√™me r√©sultat si ex√©cut√©es 2x)

```python
# ‚ùå Pas idempotent
@celery.task
def increment_counter(user_id):
    user.counter += 1  # Si retry ‚Üí +2 au lieu de +1

# ‚úÖ Idempotent
@celery.task
def set_status(user_id, status):
    user.status = status  # Si retry ‚Üí m√™me r√©sultat
```

### 5. Timeouts

```python
celery.conf.update(
    task_time_limit=1800,        # 30 min (hard kill)
    task_soft_time_limit=1700,   # 28 min (exception)
)

@celery.task
def long_task():
    try:
        # Traitement long
        process()
    except SoftTimeLimitExceeded:
        # Cleanup avant hard kill
        cleanup()
        raise
```

---

## Troubleshooting

### Probl√®me: T√¢ches non ex√©cut√©es

**Diagnostic:**
```bash
# Workers tournent ?
ps aux | grep celery

# Queues ont des t√¢ches ?
redis-cli LLEN celery:ingest

# Workers √©coutent les bonnes queues ?
celery -A app.workers.celery_app inspect active_queues
```

**Solution:**
```bash
# Restart workers
pkill -f "celery.*worker"
celery -A app.workers.celery_app worker -Q ingest -l info
```

### Probl√®me: Beat ne schedule pas

**Diagnostic:**
```bash
# Beat tourne ?
ps aux | grep "celery.*beat"

# Lock file coinc√© ?
ls -la celerybeat-schedule*
```

**Solution:**
```bash
# Supprimer lock
rm -f celerybeat-schedule.db

# Restart Beat
celery -A app.workers.celery_app beat -l info
```

### Probl√®me: Redis OOM

**Diagnostic:**
```bash
redis-cli INFO memory
# used_memory: 250mb / maxmemory: 256mb ‚ö†Ô∏è
```

**Solution:**
```bash
# Augmenter m√©moire (redis.conf)
maxmemory 1gb

# Ou purger anciens r√©sultats
redis-cli KEYS celery-task-result:* | xargs redis-cli DEL

# Ou configurer TTL auto
celery.conf.result_expires = 3600  # 1h
```

---

## Migration History

### V1.0 (Avant - Legacy)

```
FastAPI (Batch Scanner asyncio loop)
‚îî‚îÄ DMs trait√©s dans le process FastAPI
‚îî‚îÄ ‚ùå Single point of failure
```

### V2.0 (Actuel - Celery)

```
Celery Beat (0.5s schedule)
‚îî‚îÄ Envoie task scan_redis_batches
    ‚îî‚îÄ Worker Ingest ex√©cute
        ‚úÖ Robuste
        ‚úÖ Scalable
        ‚úÖ Architecture coh√©rente
```

**Voir:** `/workspace/BATCH_SCANNER_MIGRATION.md`

---

## Related Documentation

- **Cours complet:** `/workspace/CELERY_REDIS_COURS_COMPLET.md`
- **Migration:** `/workspace/BATCH_SCANNER_MIGRATION.md`
- **Docker Setup:** `.agent/SOP/DOCKER_SETUP.md`
- **Architecture globale:** `.agent/System/ARCHITECTURE.md`
- **Workers config:** Voir ce fichier

---

**Version:** 2.0
**Derni√®re mise √† jour:** 2025-10-20
**Status:** ‚úÖ Production Ready
