# Topic Modeling System - BERTopic + Gemini

**Date:** 2025-10-23
**Version:** 2.1 (BERTopic representation_model with LangChain + Gemini)
**Status:** Implemented âœ…

## ðŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [Technologies](#technologies)
4. [Composants](#composants)
5. [Flux de donnÃ©es](#flux-de-donnÃ©es)
6. [Base de donnÃ©es](#base-de-donnÃ©es)
7. [Celery Tasks](#celery-tasks)
8. [CoÃ»ts et performance](#coÃ»ts-et-performance)
9. [Configuration](#configuration)
10. [Monitoring](#monitoring)

---

## Vue d'ensemble

Le systÃ¨me de topic modeling analyse automatiquement les conversations pour identifier les thÃ¨mes rÃ©currents (refunds, shipping issues, product questions, etc.) et gÃ©nÃ©rer des insights pour l'utilisateur.

### Objectifs

- âœ… **Analyse automatique** des conversations entrantes
- âœ… **Clustering intelligent** avec BERTopic (UMAP + HDBSCAN)
- âœ… **Labels descriptifs** gÃ©nÃ©rÃ©s automatiquement par BERTopic + LangChain + Gemini
- âœ… **Mise Ã  jour quotidienne** (daily fit + merge)
- âœ… **Multi-tenant** (isolation par user_id)
- âœ… **CoÃ»t optimisÃ©** (100% gratuit pour embeddings)
- âœ… **Zero stockage embeddings** (gÃ©nÃ©ration on-the-fly)
- âœ… **Code simplifiÃ©** (85% rÃ©duction logique topic naming)

### Cas d'usage

1. **Dashboard Analytics**: Afficher les topics tendances
2. **Auto-tagging**: Classifier automatiquement les conversations
3. **Insights business**: Identifier les problÃ¨mes rÃ©currents
4. **Knowledge base**: CrÃ©er FAQ automatiquement

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         TOPIC MODELING PIPELINE (DAILY FIT+MERGE)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Messages  â”‚ (conversation_messages - Last 24h)
â”‚  (Inbound only) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: FETCH + EMBED ON-THE-FLY (Gemini)                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ - Service: get_recent_messages_and_generate_embeddings()        â”‚
â”‚ - Model: gemini-embedding-001                                   â”‚
â”‚ - Task type: 'clustering' (optimized for topic modeling)        â”‚
â”‚ - Dimensions: 768                                                â”‚
â”‚ - Batch size: 100 messages max                                  â”‚
â”‚ - âš¡ NO STORAGE: Embeddings generated and used immediately      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: FIT NEW MODEL (BERTopic)                                â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ - Algorithm: UMAP â†’ HDBSCAN â†’ c-TF-IDF                          â”‚
â”‚ - Min cluster size: 5 messages (daily data)                     â”‚
â”‚ - Fresh embeddings: Generated on-the-fly                        â”‚
â”‚ - Output: new_model fitted on last 24h messages                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: MERGE WITH YESTERDAY'S MODEL                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ - Download yesterday's model from Supabase Storage              â”‚
â”‚ - BERTopic.merge_models([yesterday_model, new_model])           â”‚
â”‚ - Merges via topic embeddings comparison (NO doc embeddings!)   â”‚
â”‚ - Output: merged_model combining all historical knowledge       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: TOPIC NAMING (BERTopic + LangChain + Gemini) âœ¨        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ - representation_model: LangChain wrapper for Gemini            â”‚
â”‚ - Auto-generated labels: BERTopic handles naming automatically  â”‚
â”‚ - Model: ChatGoogleGenerativeAI (gemini-2.0-flash-exp)         â”‚
â”‚ - Temperature: 0 (deterministic)                                â”‚
â”‚ - Extracted from: BERTopic's 'Name' column                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORAGE: BERTopic Models                                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ 1. bertopic_models (PostgreSQL) - Metadata                      â”‚
â”‚    - Model version, storage path, topic count                   â”‚
â”‚    - Date range (24h), is_active flag                           â”‚
â”‚    - Topic labels (JSONB)                                        â”‚
â”‚                                                                  â”‚
â”‚ 2. Supabase Storage (S3) - Model files                          â”‚
â”‚    - Bucket: bertopic-models                                     â”‚
â”‚    - Path: {user_id}/{version}/model.safetensors                â”‚
â”‚    - Format: safetensors (fast load/save)                       â”‚
â”‚    - Versioning: Daily (YYYYMMDD_HHMMSS)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: topic_analysis (PostgreSQL) - TOP 10 ONLY               â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ - âš¡ OVERWRITE STRATEGY: Delete old + Insert new top 10        â”‚
â”‚ - topic_id, topic_label, topic_keywords                         â”‚
â”‚ - message_count, sample_messages (last 5)                       â”‚
â”‚ - Snapshot of current top topics (updated daily)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technologies

### Core

| Composant | Technologie | Version | RÃ´le |
|-----------|-------------|---------|------|
| **Topic Modeling** | BERTopic | 0.16.0 | Clustering UMAP + HDBSCAN |
| **Embeddings** | Gemini | gemini-embedding-001 | Vector generation (768d) |
| **Topic Naming** | BERTopic + LangChain + Gemini | 2.1.12 | Auto-generated labels |
| **LLM Integration** | langchain-google-genai | 2.1.12 | ChatGoogleGenerativeAI wrapper |
| **Vector DB** | pgvector | Latest | Similarity search |
| **Storage** | Supabase Storage | S3-compatible | Model persistence |
| **Serialization** | safetensors | 0.4.2 | Fast model save/load |

### Dependencies

```python
# Topic modeling
bertopic==0.16.0
umap-learn==0.5.5
hdbscan==0.8.38
scikit-learn==1.4.1.post1
safetensors==0.4.2
langchain-google-genai==2.1.12  # NEW: LangChain + Gemini integration

# Already installed
google-genai==1.34.0  # For embeddings only
numpy==2.3.2
```

---

## Composants

### 1. TopicModelingService

**Fichier:** `/workspace/backend/app/services/topic_modeling_service.py`

**ResponsabilitÃ©s:**

```python
class TopicModelingService:
    """Service for BERTopic-based topic modeling with Gemini"""

    def __init__(user_id: str):
        # Initialize LangChain Gemini LLM for topic naming
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0,
            google_api_key=gemini_api_key
        )
        self.representation_model = BERTopicLangChain(llm)  # Auto topic naming!

    # EMBEDDINGS (ON-THE-FLY)
    async def get_recent_messages_and_generate_embeddings(hours_lookback: int) -> Tuple

    # MODEL STORAGE
    async def upload_model_to_storage(model: BERTopic, version: str) -> str
    async def download_model_from_storage(version: str) -> BERTopic

    # MODEL OPERATIONS
    async def fit_initial_model(min_documents: int = 10) -> Optional[str]
    async def merge_and_update_model(min_documents: int = 10) -> Optional[str]

    # HELPERS
    async def _save_topics_to_db(model, texts, topics, topic_labels)
```

**CaractÃ©ristiques clÃ©s:**

- âœ… **RÃ©utilise `embed_texts()`** existant (pas de duplication)
- âœ… **Batch processing** (100 messages max par batch Gemini)
- âœ… **Auto topic naming** via BERTopic representation_model (plus de code custom!)
- âœ… **Error handling** robuste avec rollback
- âœ… **Logging dÃ©taillÃ©** pour monitoring
- âœ… **Multi-tenant** (isolation par user_id)

### 2. embed_texts() - Infrastructure partagÃ©e

**Fichier:** `/workspace/backend/app/services/ingest_helpers.py`

**Modification:**

```python
def embed_texts(
    batch: List[str],
    model: str='gemini-embedding-001',
    task_type: str='retrieval_document'  # â† NEW: Configurable!
) -> List[List[float]]:
    """
    Generate embeddings with Gemini

    Task types:
    - 'retrieval_document' â†’ RAG indexing (default)
    - 'retrieval_query' â†’ RAG queries
    - 'clustering' â†’ Topic modeling âœ…
    - 'classification' â†’ Classification
    - 'semantic_similarity' â†’ Similarity
    """
    config = types.EmbedContentConfig(
        task_type=task_type,  # Now configurable!
        output_dimensionality=768
    )
```

**Avantage:** RÃ©utilisation totale de l'infrastructure existante

---

## Flux de donnÃ©es

### Daily Fit + Merge (3:00 AM UTC)

```
For each user:
    â†“
Get messages from last 24h (conversation_messages)
    â†“
    â”‚ < 10 messages? â†’ SKIP (logger.info)
    â”‚ â‰¥ 10 messages? â†’ Continue â†“
    â†“
generate_embeddings_batch(texts, task_type='clustering')
âš¡ Embeddings kept in memory ONLY (not stored)
    â†“
BERTopic.fit(texts, embeddings) â†’ new_model
    â†“
download_model_from_storage(yesterday_version)
â”‚ No model exists (Day 2)? â†’ Use new_model as initial
â”‚ Model exists (Day 3+)? â†’ Continue â†“
    â†“
BERTopic.merge_models([yesterday_model, new_model]) â†’ merged_model
    â†“
Transform ONLY new messages (last 24h) with merged_model
    â†“
generate_topic_labels_batch() â†’ Gemini 2.5 Flash
    â†“
upload_model_to_storage(new_version) â†’ Supabase Storage
    â†“
Save metadata â†’ bertopic_models (is_active=TRUE, old deactivated)
    â†“
Delete old topic_analysis entries
    â†“
Save top 10 topics â†’ topic_analysis
âš¡ Embeddings discarded (freed from memory)
```

**Temps estimÃ©:** 20-40s par user

**Ã‰conomies vs ancien systÃ¨me:**
- âŒ Plus de stockage embeddings (GBs saved)
- âŒ Plus de query `get_embeddings()` sur DB
- âœ… 1 seule tÃ¢che au lieu de 2
- âœ… ModÃ¨le toujours Ã  jour (daily vs biweekly)

---

## Base de donnÃ©es

### Tables

#### 1. bertopic_models

**Stockage:** PostgreSQL (metadata only)

```sql
CREATE TABLE bertopic_models (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES auth.users(id),
    model_version TEXT NOT NULL,  -- Format: YYYYMMDD_HHMMSS
    storage_path TEXT NOT NULL,   -- Supabase Storage path
    total_topics INT NOT NULL DEFAULT 0,
    total_documents INT NOT NULL DEFAULT 0,
    date_range_start TIMESTAMPTZ NOT NULL,
    date_range_end TIMESTAMPTZ NOT NULL,
    is_active BOOLEAN DEFAULT FALSE,  -- Only one active per user
    metadata JSONB DEFAULT '{}',      -- topic_labels, hyperparams, etc.
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),

    CONSTRAINT unique_user_model_version UNIQUE (user_id, model_version)
);

-- Trigger: Ensure only one active model per user
CREATE TRIGGER trigger_ensure_single_active_bertopic_model
BEFORE INSERT OR UPDATE ON bertopic_models
FOR EACH ROW WHEN (NEW.is_active = TRUE)
EXECUTE FUNCTION ensure_single_active_bertopic_model();
```

#### 2. topic_analysis

**Stockage:** PostgreSQL

**Usage:** Stores TOP 10 topics only (overwritten daily)

```sql
CREATE TABLE topic_analysis (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES auth.users(id),
    topic_id INT NOT NULL,
    topic_label TEXT NOT NULL,           -- Gemini-generated label
    topic_keywords TEXT[] NOT NULL,      -- Top keywords
    message_count INT NOT NULL,
    sample_messages TEXT[],              -- Top 5 sample messages
    analysis_date DATE DEFAULT CURRENT_DATE,
    date_range_start TIMESTAMPTZ NOT NULL,  -- Last 24h start
    date_range_end TIMESTAMPTZ NOT NULL,    -- Last 24h end
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE topic_analysis IS 'Stores top 10 topics from daily BERTopic analysis (overwritten daily per user)';
```

**Note importante:** Ã€ chaque daily fit+merge, on DELETE les anciennes entrÃ©es du user et INSERT les nouvelles top 10. C'est une stratÃ©gie "snapshot" plutÃ´t qu'historique.

### Supabase Storage

**Bucket:** `bertopic-models`

**Structure:**
```
bertopic-models/
â”œâ”€â”€ {user_id_1}/
â”‚   â”œâ”€â”€ 20251021_040000/
â”‚   â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”‚   â””â”€â”€ config.json
â”‚   â”œâ”€â”€ 20251023_040000/
â”‚   â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”‚   â””â”€â”€ config.json
â”œâ”€â”€ {user_id_2}/
â”‚   â””â”€â”€ ...
```

**RLS Policies:**
```sql
-- Users can only access their own models
CREATE POLICY "Users can upload their own BERTopic models"
ON storage.objects FOR INSERT TO authenticated
WITH CHECK (
    bucket_id = 'bertopic-models'
    AND (storage.foldername(name))[1] = auth.uid()::text
);
```

---

## Celery Tasks

### Configuration

**Fichier:** `/workspace/backend/app/workers/celery_app.py`

```python
# Task routing
task_routes = {
    "app.workers.topics.*": {"queue": "topics"},
}

# Beat schedule
beat_schedule = {
    "topic-modeling-daily-fit-merge": {
        "task": "app.workers.topics.run_daily_fit_and_merge",
        "schedule": crontab(hour=3, minute=0),  # 3:00 AM UTC daily
        "options": {"expires": 7200},  # 2 hours timeout
    },
}
```

### Tasks

**Fichier:** `/workspace/backend/app/workers/topics.py`

#### 1. run_daily_fit_and_merge

```python
@celery.task(name="app.workers.topics.run_daily_fit_and_merge")
def run_daily_fit_and_merge() -> Dict[str, Any]:
    """
    Daily fit + merge workflow
    Runs: Every day at 3:00 AM UTC

    Workflow per user:
    1. Fetch last 24h inbound messages
    2. Generate embeddings on-the-fly
    3. Fit new model on these messages
    4. Merge with yesterday's model (if exists)
    5. Save top 10 topics (overwrite old ones)
    """
    # Get all users
    # For each user:
    #   - Get messages from last 24h
    #   - Skip if < 10 messages
    #   - Generate embeddings on-the-fly
    #   - Fit new model
    #   - Download yesterday's model (if exists)
    #   - Merge models
    #   - Upload new version
    #   - Save top 10 topics
```

**CapacitÃ©:** ~200+ users (avec timeout 2h)

**Temps estimÃ©:** 20-40s par user

#### 2. fit_initial_model_for_user

```python
@celery.task(name="app.workers.topics.fit_initial_model_for_user")
def fit_initial_model_for_user(user_id: str) -> Dict[str, Any]:
    """
    One-time task: Fit initial model for a user
    Triggered: Manually or automatically when user has no active model

    Fits on last 24h messages with on-the-fly embedding generation
    """
    # Fetch last 24h messages
    # Skip if < 10 messages
    # Generate embeddings on-the-fly
    # Fit initial model
    # Upload to storage + save metadata
```

**Note:** Cette tÃ¢che n'est appelÃ©e que le premier jour (J2) oÃ¹ le user a au moins 10 messages. Les jours suivants, `run_daily_fit_and_merge` gÃ¨re tout.

---

## CoÃ»ts et performance

### CoÃ»ts (par 10K messages/mois)

| Service | Ancien (OpenAI) | Nouveau (Gemini) | Ã‰conomie |
|---------|------------------|-------------------|----------|
| **Embeddings** | $0.20/mois | **GRATUIT** âœ… | 100% |
| **Topic naming** | GPT-4o: $2.50 | Flash 2.0: $0.08 | 97% |
| **Stockage DB** | 6.1 KB/msg | 3 KB/msg | 50% |
| **TOTAL** | **$2.70/mois** | **$0.08/mois** | **97%** |

**Quotas Gemini (gratuits):**
- Embeddings: 15M requÃªtes/mois
- Flash 2.0: 1500 requÃªtes/jour

### Performance

#### Latence embeddings

| Batch size | OpenAI | Gemini | Gagnant |
|------------|--------|--------|---------|
| 1 message | 50-100ms | 50-100ms | Ã‰galitÃ© |
| 100 messages | 200-500ms | 150-400ms | Gemini âœ… |

#### Latence topic naming

| Topics | SÃ©quentiel (20 calls) | Batch (1 call) | Gain |
|--------|------------------------|----------------|------|
| 20 topics | 20-40s | 1-2s | **20x** âœ… |

#### Storage

| Format | Taille | Load time | Recommandation |
|--------|--------|-----------|----------------|
| pickle | 15-25 MB | 3-5s | âŒ Deprecated |
| safetensors | 10-15 MB | 0.5-1s | âœ… UtilisÃ© |

---

## Configuration

### Variables d'environnement

```bash
# Gemini API (required)
GEMINI_API_KEY=your_gemini_api_key

# Supabase (required)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Celery (required)
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0
```

### HyperparamÃ¨tres BERTopic

**Fichier:** `topic_modeling_service.py`

```python
# Initial fit
BERTopic(
    embedding_model=None,        # Use pre-computed embeddings
    min_topic_size=10,           # Min messages per topic
    nr_topics="auto",            # Auto-determine number of topics
    calculate_probabilities=False,  # Faster (skip probability calc)
    verbose=True
)
```

**Ajustements possibles:**

- `min_topic_size`: 5-20 (plus petit = plus de topics)
- `nr_topics`: "auto" ou nombre fixe
- `calculate_probabilities`: True si besoin des probas

---

## Monitoring

### Logs Celery

```bash
# Check daily inference logs
grep "[TOPIC DAILY]" celery.log

# Check refit logs
grep "[TOPIC REFIT]" celery.log

# Check errors
grep "ERROR.*TOPIC" celery.log
```

**MÃ©triques importantes:**

```python
{
  "total_users": 25,
  "processed_users": 25,
  "failed_users": 0,
  "total_messages_processed": 1250,
  "duration_seconds": 312.5,
  "estimated_time_per_user_seconds": 12.5  # â† Surveiller
}
```

### Flower (Celery Monitoring)

**URL:** http://localhost:5555

**MÃ©triques:**
- Task success/failure rate
- Execution time per task
- Queue depth
- Worker status

### Database Queries

```sql
-- Check active models
SELECT user_id, model_version, total_topics, total_documents
FROM bertopic_models
WHERE is_active = TRUE;

-- Check topic analysis (last 7 days)
SELECT topic_label, message_count
FROM topic_analysis
WHERE date_range_start >= NOW() - INTERVAL '7 days'
ORDER BY message_count DESC
LIMIT 10;

-- Check embeddings count per user
SELECT user_id, COUNT(*) as embedding_count
FROM message_embeddings
GROUP BY user_id
ORDER BY embedding_count DESC;
```

### Alertes recommandÃ©es

**Sentry / Logging:**

```python
# Si timeout proche
if duration > (timeout * 0.8):
    logger.warning(f"Task approaching timeout: {duration}s / {timeout}s")

# Si taux d'Ã©chec Ã©levÃ©
if failed_users > (total_users * 0.2):
    logger.error(f"High failure rate: {failed_users}/{total_users}")

# Si pas assez de documents
if document_count < min_documents:
    logger.info(f"Not enough documents: {document_count} < {min_documents}")
```

---

## Related docs

### Core System
- `.agent/System/ARCHITECTURE.md` - Architecture globale
- `.agent/System/DATABASE_SCHEMA.md` - SchÃ©ma DB complet
- `.agent/System/CELERY_ARCHITECTURE.md` - Workers et Beat

### Infrastructure
- `.agent/SOP/DOCKER_SETUP.md` - Docker Compose setup
- `/workspace/TOPIC_MODELING_PERFORMANCE.md` - Guide performance
- `/workspace/TOPIC_MODELING_GEMINI_REFACTOR.md` - DÃ©tails refactorisation

### Related Features
- `.agent/Tasks/CLUSTERING.md` - PRD original
- `.agent/Tasks/ANALYTICS_KPI.md` - Analytics dashboard

---

## Changelog

### Version 2.1 (2025-10-23) - BERTopic representation_model (LangChain + Gemini)

**Changements majeurs:**
- âœ… Ajout `langchain-google-genai==2.1.12` Ã  requirements.txt
- âœ… Utilisation de BERTopic's built-in `representation_model` pour topic naming
- âœ… Suppression de `generate_topic_labels_batch()` (50 lignes de code custom)
- âœ… Extraction labels depuis BERTopic's `Name` column (auto-gÃ©nÃ©rÃ©s)
- âœ… ~85% rÃ©duction de la logique de topic naming

**Code avant (V2.0):**
```python
# Custom batch processing avec Gemini API directement
async def generate_topic_labels_batch(topics_data):
    # 50 lignes de code...
    response = self.gemini_model.generate_content(prompt)
    # Manual parsing...
```

**Code aprÃ¨s (V2.1):**
```python
# BERTopic gÃ¨re tout automatiquement
def __init__(user_id):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-exp", temperature=0)
    self.representation_model = BERTopicLangChain(llm)

# Usage dans fit_initial_model / merge_and_update_model
topic_model = BERTopic(
    representation_model=self.representation_model,  # Auto naming!
)
# Labels extracted from: row['Name']
```

**BÃ©nÃ©fices:**
- ðŸš€ Code plus simple et maintenable
- ðŸ“¦ Utilise les best practices BERTopic officielles
- ðŸ”§ Moins de code custom Ã  maintenir
- âœ… MÃªme fonctionnalitÃ©, moins de complexitÃ©

**Migration:**
```bash
# Installer nouvelle dÃ©pendance
pip install langchain-google-genai==2.1.12

# Aucune migration DB requise (changement code seulement)
```

### Version 2.0 (2025-10-23) - Daily Fit+Merge sans stockage embeddings

**Changements majeurs:**
- âŒ Suppression table `message_embeddings` (Ã©conomie GBs de stockage)
- âœ… Embeddings gÃ©nÃ©rÃ©s on-the-fly uniquement pour nouveaux messages
- âœ… 1 seule tÃ¢che quotidienne (fit + merge) au lieu de 2 tÃ¢ches sÃ©parÃ©es
- âœ… Top 10 topics stockÃ©s avec stratÃ©gie overwrite
- âœ… Mise Ã  jour quotidienne (vs biweekly refit)
- âœ… Merge via topic embeddings (pas besoin des document embeddings)

**Migration:**
```bash
# Appliquer migration
psql $DATABASE_URL < migrations/20251023_remove_message_embeddings.sql
```

### Version 1.0 (2025-10-21) - Gemini-optimized

- Migration de OpenAI vers Gemini (Ã©conomie 97%)
- Utilisation de safetensors pour storage
- Batch processing pour topic naming

---

**DerniÃ¨re mise Ã  jour:** 2025-10-23
**Auteur:** Claude Code
**Version:** 2.1 (BERTopic representation_model with LangChain + Gemini)
