# Cours Complet: Celery, Redis & Architecture Distribu√©e

**Date:** 2025-10-20
**Niveau:** D√©butant ‚Üí Interm√©diaire
**Dur√©e lecture:** 15-20 min

---

## üìö Table des Mati√®res

1. [Le Probl√®me √† R√©soudre](#le-probl√®me-√†-r√©soudre)
2. [Redis: La Messagerie](#redis-la-messagerie)
3. [Celery Worker: Le Travailleur](#celery-worker-le-travailleur)
4. [Celery Beat: L'Horloge](#celery-beat-lhorloge)
5. [Architecture Compl√®te](#architecture-compl√®te)
6. [Cas Pratique: SocialSync AI](#cas-pratique-socialsync-ai)
7. [Commandes Essentielles](#commandes-essentielles)
8. [Troubleshooting](#troubleshooting)

---

## 1. Le Probl√®me √† R√©soudre

### Sans Celery (Approche Na√Øve)

Imagine une API FastAPI qui doit:
- Recevoir un webhook WhatsApp
- Traiter le message avec l'IA (10 secondes)
- Envoyer la r√©ponse

**Code na√Øf:**
```python
@app.post("/webhook")
async def webhook(message: dict):
    # ‚è∞ 10 secondes d'attente ici
    response = await process_with_ai(message)
    await send_response(response)
    return {"status": "ok"}
```

**Probl√®mes:**
1. ‚è∞ **Timeout**: Meta attend une r√©ponse en < 5s, sinon il retry
2. üîí **Blocage**: Pendant 10s, l'API ne peut rien faire d'autre
3. üí• **Crash**: Si FastAPI crash ‚Üí t√¢che perdue
4. üìà **Scalabilit√©**: Impossible de parall√©liser

### Solution: Architecture Distribu√©e

**Principe:**
1. API re√ßoit webhook ‚Üí Envoie t√¢che √† une **queue** ‚Üí R√©pond imm√©diatement "OK"
2. **Worker** prend la t√¢che dans la queue ‚Üí Traite avec AI ‚Üí Envoie r√©ponse
3. Si API crash ‚Üí Worker continue de travailler ‚úÖ

**C'est exactement ce que fait Celery + Redis !**

---

## 2. Redis: La Messagerie üì¨

### Qu'est-ce que Redis ?

**Redis = Base de donn√©es en m√©moire ultra-rapide**

Imagine Redis comme un **tableau d'affichage** dans une entreprise:
- Quelqu'un √©crit un post-it et le colle
- Quelqu'un d'autre lit le post-it et le prend
- Tout le monde peut lire/√©crire en m√™me temps

### R√¥le 1: Broker (File d'attente de messages)

**Analogie:** Redis = La bo√Æte aux lettres

```
FastAPI (producteur) ‚Üí Redis Queue ‚Üí Celery Worker (consommateur)
   üìÆ "Task: Process message"  ‚Üí  üì¨  ‚Üí  üë∑ "Je prends!"
```

**En pratique:**
```python
# FastAPI envoie une t√¢che
task = process_message.delay(message_id="123")
# ‚Üì Redis stocke √ßa:
# Queue "ingest": [{"task": "process_message", "args": ["123"]}]

# Worker lit la queue
# ‚Üì Redis retire la t√¢che de la queue
# Worker ex√©cute: process_message("123")
```

### R√¥le 2: Result Backend (Stockage des r√©sultats)

**Analogie:** Redis = Le casier de r√©sultats

```python
# Worker termine la t√¢che
result = {"status": "success", "response": "Hello"}

# Stocke dans Redis
task_id = "abc-123-def"
redis.set(f"celery-task-result:{task_id}", result)

# FastAPI peut r√©cup√©rer le r√©sultat plus tard
result = task.get()
```

### Structure Redis pour Celery

```redis
# Queues (listes Redis)
LPUSH celery:ingest '{"task": "process_message", "id": "123"}'
RPOP celery:ingest  # Worker prend la t√¢che

# R√©sultats (hash Redis)
SET celery-task-result:abc-123 '{"status": "SUCCESS", "result": {...}}'

# M√©tadonn√©es
SET celery-task-meta:abc-123 '{"state": "PENDING", "retries": 0}'
```

**Pourquoi Redis et pas une BDD ?**

| Redis | PostgreSQL |
|-------|------------|
| ‚ö° En RAM (ultra rapide) | üíæ Sur disque (lent) |
| üìä 100k ops/sec | üìä 1k ops/sec |
| ‚ùå Donn√©es volatiles (TTL) | ‚úÖ Donn√©es persistantes |
| ‚úÖ Parfait pour queues | ‚ùå Overhead pour queues |

---

## 3. Celery Worker: Le Travailleur üë∑

### Qu'est-ce qu'un Worker ?

**Worker = Process Python qui √©coute Redis et ex√©cute des t√¢ches**

**Analogie:** Imagine un restaurant

- **Redis Queue** = Le passe-plat (commandes en attente)
- **Celery Worker** = Le cuisinier qui prend les commandes et cuisine
- **Plusieurs Workers** = Plusieurs cuisiniers en parall√®le

### D√©marrage d'un Worker

```bash
celery -A app.workers.celery_app worker --loglevel=info -Q ingest
#       ‚îÇ                        ‚îÇ                         ‚îÇ
#       ‚îÇ                        ‚îÇ                         ‚îî‚îÄ Queue(s) √† √©couter
#       ‚îÇ                        ‚îî‚îÄ Commande: "worker"
#       ‚îî‚îÄ App Celery (configuration)
```

**Ce qu'il fait:**
1. Se connecte √† Redis
2. √âcoute la queue `ingest`
3. Prend une t√¢che d√®s qu'elle arrive
4. Ex√©cute le code Python
5. Stocke le r√©sultat dans Redis
6. Recommence (boucle infinie)

### Exemple: Notre Worker

**Fichier:** `backend/app/workers/ingest.py`

```python
@celery.task(bind=True, name="app.workers.ingest.process_document")
def process_document_task(self, document_id: str):
    # 1. Worker prend cette t√¢che dans la queue "ingest"
    # 2. Ex√©cute ce code
    db = get_db()
    doc = db.table("knowledge_documents").select(...).execute()

    # 3. Traitement long (10s, 1 min, peu importe)
    process_pdf(doc)

    # 4. R√©sultat stock√© dans Redis automatiquement
    return {"status": "success", "doc_id": document_id}
```

**Envoyer la t√¢che:**
```python
# Depuis FastAPI
from app.workers.ingest import process_document_task

@app.post("/documents")
async def upload_document(doc_id: str):
    # Envoie la t√¢che √† Redis
    task = process_document_task.delay(doc_id)

    # R√©pond IMM√âDIATEMENT (< 100ms)
    return {"task_id": task.id, "status": "processing"}
```

### Concurrence: Multiple Workers

**Tu peux lancer PLUSIEURS workers:**

```bash
# Terminal 1: Worker 1
celery -A app.workers.celery_app worker -Q ingest -n worker1@%h

# Terminal 2: Worker 2
celery -A app.workers.celery_app worker -Q ingest -n worker2@%h

# Terminal 3: Worker 3
celery -A app.workers.celery_app worker -Q ingest -n worker3@%h
```

**Redis distribue les t√¢ches:**
```
Redis Queue: [Task1, Task2, Task3, Task4, Task5]
              ‚Üì      ‚Üì      ‚Üì      ‚Üì      ‚Üì
           Worker1 Worker2 Worker3 Worker1 Worker2
```

**R√©sultat:** 5x plus rapide ! üöÄ

---

## 4. Celery Beat: L'Horloge ‚è∞

### Qu'est-ce que Celery Beat ?

**Celery Beat = Cron job distribu√© (scheduler de t√¢ches p√©riodiques)**

**Analogie:** Imagine un r√©veil qui sonne

- **Celery Beat** = Le r√©veil (envoie des t√¢ches √† intervalles r√©guliers)
- **Redis Queue** = La sonnerie retentit
- **Worker** = Tu te r√©veilles et tu fais l'action

### Diff√©rence Worker vs Beat

| Celery Worker | Celery Beat |
|---------------|-------------|
| **Ex√©cute** les t√¢ches | **Planifie** les t√¢ches |
| √âcoute Redis | Envoie vers Redis |
| Peut y en avoir plusieurs | **UN SEUL** (master) |
| Obligatoire | Optionnel |

**Important:**
- ‚úÖ Worker sans Beat = OK (t√¢ches manuelles uniquement)
- ‚ùå Beat sans Worker = Inutile (envoie des t√¢ches, mais personne pour les faire)

### Configuration Beat

**Fichier:** `backend/app/workers/celery_app.py`

```python
celery.conf.beat_schedule = {
    "scan-redis-batches-every-500ms": {
        "task": "app.workers.ingest.scan_redis_batches",  # Quelle t√¢che
        "schedule": 0.5,  # Quand (0.5s = toutes les 500ms)
        "options": {
            "expires": 0.4,  # Expire si pas ex√©cut√©e en 400ms
        }
    },
    "poll-comments-every-5-minutes": {
        "task": "app.workers.comments.poll_post_comments",
        "schedule": 300.0,  # Toutes les 5 minutes
    },
}
```

### D√©marrage de Beat

```bash
celery -A app.workers.celery_app beat --loglevel=info
#                                ‚îÇ
#                                ‚îî‚îÄ Commande: "beat" (pas "worker")
```

**Ce qu'il fait:**
```
T=0s   ‚Üí Beat: "Envoi task scan_redis_batches vers Redis queue 'ingest'"
T=0.5s ‚Üí Beat: "Envoi task scan_redis_batches vers Redis queue 'ingest'"
T=1s   ‚Üí Beat: "Envoi task scan_redis_batches vers Redis queue 'ingest'"
...

En parall√®le:
Worker: "Je prends task scan_redis_batches" ‚Üí Ex√©cute ‚Üí Termine
Worker: "Je prends task scan_redis_batches" ‚Üí Ex√©cute ‚Üí Termine
```

### Types de Schedules

```python
from celery.schedules import crontab

celery.conf.beat_schedule = {
    # Toutes les 30 secondes
    "simple": {
        "task": "my_task",
        "schedule": 30.0,
    },

    # Tous les jours √† 8h du matin
    "daily": {
        "task": "send_daily_report",
        "schedule": crontab(hour=8, minute=0),
    },

    # Tous les lundis √† 9h
    "weekly": {
        "task": "weekly_cleanup",
        "schedule": crontab(day_of_week=1, hour=9, minute=0),
    },

    # Toutes les heures
    "hourly": {
        "task": "check_status",
        "schedule": crontab(minute=0),
    },
}
```

---

## 5. Architecture Compl√®te

### Vue d'Ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SYST√àME COMPLET                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Redis     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇCelery Worker ‚îÇ
‚îÇ  (Producteur)‚îÇ     ‚îÇ   (Broker)   ‚îÇ     ‚îÇ(Consommateur)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                      ‚ñ≤                     ‚îÇ
      ‚îÇ                      ‚îÇ                     ‚îÇ
      ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
      ‚îÇ              ‚îÇ  Celery Beat  ‚îÇ             ‚îÇ
      ‚îÇ              ‚îÇ  (Scheduler)  ‚îÇ             ‚îÇ
      ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
      ‚îÇ                                            ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PostgreSQL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    (Donn√©es m√©tier)
```

### Flux de Donn√©es

#### Sc√©nario 1: T√¢che Manuelle (DM WhatsApp)

```
1. WhatsApp ‚Üí Webhook ‚Üí FastAPI
   User envoie "Hello" ‚Üí Meta webhook ‚Üí POST /api/whatsapp/webhook

2. FastAPI ‚Üí Redis
   @app.post("/webhook")
   async def webhook(data):
       # Sauvegarde message en BDD
       db.insert(message)

       # Envoie t√¢che √† Redis (< 10ms)
       process_message.delay(message_id)

       # R√©pond IMM√âDIATEMENT √† Meta
       return {"status": "ok"}  # ‚ö° < 100ms total

3. Redis ‚Üí Worker
   Worker √©coute queue "ingest"
   Worker prend task "process_message"

4. Worker ‚Üí Traitement
   # Appel IA (10 secondes, pas grave)
   response = await rag_agent.generate(message)

   # Envoie r√©ponse WhatsApp
   await whatsapp_api.send(response)

5. Worker ‚Üí Redis (r√©sultat)
   task.update_state(state="SUCCESS", result={"sent": true})
```

**Timeline:**
```
0ms    ‚îÇ Webhook arrive
10ms   ‚îÇ Message saved in DB
20ms   ‚îÇ Task sent to Redis
100ms  ‚îÇ FastAPI responds "OK" ‚úÖ
       ‚îÇ
1000ms ‚îÇ Worker picks task
3000ms ‚îÇ AI processing...
8000ms ‚îÇ AI processing...
10000ms‚îÇ Response generated
10500ms‚îÇ WhatsApp message sent ‚úÖ
```

#### Sc√©nario 2: T√¢che Planifi√©e (Batch Scanner)

```
1. Celery Beat ‚Üí Redis
   Beat (horloge): "C'est l'heure ! Toutes les 0.5s"
   Beat envoie: scan_redis_batches.delay()

2. Redis ‚Üí Worker
   Worker prend task "scan_redis_batches"

3. Worker ‚Üí Ex√©cution
   def scan_redis_batches():
       # Scan Redis pour batches dus
       batches = redis.get_due_batches()

       # Traite chaque batch
       for batch in batches:
           process_batch(batch)

       return {"processed": len(batches)}

4. Worker ‚Üí Redis (r√©sultat)
   task.update_state(state="SUCCESS")

5. Repeat (toutes les 0.5s)
   Beat: "Encore l'heure !"
   Beat envoie: scan_redis_batches.delay()
```

**Timeline:**
```
0ms     ‚îÇ Beat schedule tick
10ms    ‚îÇ Task sent to Redis
50ms    ‚îÇ Worker picks task
100ms   ‚îÇ Scan Redis for batches
200ms   ‚îÇ Process batches (if any)
400ms   ‚îÇ Task complete
500ms   ‚îÇ Beat schedule tick (again) ‚ôªÔ∏è
510ms   ‚îÇ Task sent to Redis
...
```

---

## 6. Cas Pratique: SocialSync AI

### Notre Architecture Actuelle

**3 Queues:**
1. `ingest` - Messages DMs/Chats (WhatsApp, Instagram)
2. `scheduler` - Posts planifi√©s
3. `comments` - Commentaires Instagram

**2 Types de T√¢ches:**
1. **Manuelles** (d√©clench√©es par √©v√©nements)
   - `process_message` - Traite un DM
   - `process_document` - Indexe un document
   - `publish_post` - Publie un post planifi√©

2. **P√©riodiques** (d√©clench√©es par Celery Beat)
   - `scan_redis_batches` - Toutes les 0.5s
   - `poll_post_comments` - Toutes les 5 min
   - `enqueue_due_posts` - Toutes les 1 min

### Commandes de D√©marrage

**Production compl√®te:**
```bash
# Terminal 1: FastAPI (API)
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Terminal 2: Worker ingest (DMs/documents)
celery -A app.workers.celery_app worker -l info -Q ingest -n ingest@%h

# Terminal 3: Worker scheduler (posts planifi√©s)
celery -A app.workers.celery_app worker -l info -Q scheduler -n scheduler@%h

# Terminal 4: Worker comments (commentaires)
celery -A app.workers.celery_app worker -l info -Q comments -n comments@%h

# Terminal 5: Celery Beat (t√¢ches p√©riodiques) ‚ö†Ô∏è REQUIS
celery -A app.workers.celery_app beat -l info

# Terminal 6: Redis (si pas d√©j√† lanc√©)
redis-server
```

**Dev simplifi√© (1 worker pour tout):**
```bash
# Terminal 1: FastAPI
uvicorn app.main:app --reload

# Terminal 2: Worker + Beat combin√©
celery -A app.workers.celery_app worker --beat -l info -Q ingest,scheduler,comments

# Terminal 3: Redis
redis-server
```

### Que se passe-t-il SANS Celery Beat ?

**Avec Beat:**
```
‚úÖ DMs trait√©s (scan_redis_batches toutes les 0.5s)
‚úÖ Comments poll√©s (toutes les 5 min)
‚úÖ Posts publi√©s (toutes les 1 min)
```

**Sans Beat:**
```
‚ùå DMs NON trait√©s (aucun scan de Redis)
‚ùå Comments NON poll√©s (pas de polling)
‚ùå Posts NON publi√©s (pas de trigger)

Mais:
‚úÖ T√¢ches manuelles OK (si envoy√©es par FastAPI)
```

**Exemple concret:**
```bash
# Scenario: Beat arr√™t√©
pkill -f "celery.*beat"

# Utilisateur envoie DM WhatsApp
# ‚Üí FastAPI re√ßoit webhook
# ‚Üí Message stock√© dans Redis batch
# ‚Üí ‚ùå JAMAIS trait√© (Beat ne scan pas Redis)
# ‚Üí ‚ùå Utilisateur n'aura jamais de r√©ponse

# Solution: Red√©marrer Beat
celery -A app.workers.celery_app beat -l info
# ‚Üí scan_redis_batches ex√©cut√© toutes les 0.5s
# ‚Üí ‚úÖ Batch trait√©, r√©ponse envoy√©e
```

---

## 7. Commandes Essentielles

### Gestion des Workers

```bash
# Lister les workers actifs
celery -A app.workers.celery_app inspect active_queues

# Voir les stats
celery -A app.workers.celery_app inspect stats

# Voir les t√¢ches en cours
celery -A app.workers.celery_app inspect active

# Arr√™ter proprement un worker
celery -A app.workers.celery_app control shutdown

# Purger une queue (vider)
celery -A app.workers.celery_app purge -Q ingest
```

### Monitoring Beat

```bash
# Voir le schedule actif
celery -A app.workers.celery_app inspect scheduled

# V√©rifier si Beat tourne
ps aux | grep "celery.*beat"

# Logs Beat
celery -A app.workers.celery_app beat -l debug
```

### Debug Redis

```bash
# Se connecter √† Redis
redis-cli

# Voir toutes les cl√©s Celery
KEYS celery*

# Voir la queue "ingest"
LRANGE celery 0 -1

# Voir les r√©sultats de t√¢ches
KEYS celery-task-result:*

# Compter les t√¢ches en attente
LLEN celery

# Vider Redis (‚ö†Ô∏è ATTENTION)
FLUSHDB
```

### Monitoring Production

**Flower (Interface Web pour Celery):**
```bash
# Installation
pip install flower

# D√©marrage
celery -A app.workers.celery_app flower --port=5555

# Acc√®s
http://localhost:5555
```

**Dashboard Flower:**
- üìä Workers actifs
- üìà Graphiques de performance
- üìã Liste des t√¢ches (en cours, succ√®s, √©checs)
- ‚è±Ô∏è Temps d'ex√©cution moyen
- üîÑ Retry logs

---

## 8. Troubleshooting

### Probl√®me 1: T√¢ches non ex√©cut√©es

**Sympt√¥mes:**
- Task envoy√©e √† Redis
- Jamais ex√©cut√©e
- Timeout c√¥t√© utilisateur

**Diagnostic:**
```bash
# 1. Worker tourne ?
ps aux | grep "celery.*worker"

# 2. Worker √©coute la bonne queue ?
celery -A app.workers.celery_app inspect active_queues
# Doit afficher: "ingest", "scheduler", "comments"

# 3. Redis contient des t√¢ches ?
redis-cli
LLEN celery  # Nombre de t√¢ches

# 4. Erreurs dans les logs ?
celery -A app.workers.celery_app worker -l debug -Q ingest
```

**Solutions:**
```bash
# Red√©marrer le worker
pkill -f "celery.*worker"
celery -A app.workers.celery_app worker -l info -Q ingest

# Si trop de t√¢ches bloqu√©es, purger
celery -A app.workers.celery_app purge -Q ingest
```

---

### Probl√®me 2: Beat ne schedule pas

**Sympt√¥mes:**
- `scan_redis_batches` pas ex√©cut√© toutes les 0.5s
- DMs non trait√©s

**Diagnostic:**
```bash
# 1. Beat tourne ?
ps aux | grep "celery.*beat"

# 2. Schedule configur√© ?
celery -A app.workers.celery_app inspect scheduled

# 3. Logs Beat
celery -A app.workers.celery_app beat -l debug
```

**Solutions:**
```bash
# Beat utilise un fichier de lock
# Si Beat crash, le lock reste
rm -f celerybeat-schedule.db

# Red√©marrer Beat
celery -A app.workers.celery_app beat -l info
```

---

### Probl√®me 3: T√¢ches dupliqu√©es

**Sympt√¥mes:**
- M√™me t√¢che ex√©cut√©e 2x, 3x
- Utilisateur re√ßoit plusieurs r√©ponses

**Causes:**
1. Plusieurs Beat lanc√©s (interdit !)
2. Pas de lock Redis (nos batches ont un lock ‚úÖ)

**Diagnostic:**
```bash
# Combien de Beat actifs ?
ps aux | grep "celery.*beat" | wc -l
# Doit retourner: 1 (UN SEUL)

# Si > 1, kill tous sauf 1
pkill -f "celery.*beat"
celery -A app.workers.celery_app beat -l info
```

---

### Probl√®me 4: Redis plein

**Sympt√¥mes:**
- Redis erreur "OOM (Out Of Memory)"
- T√¢ches rejet√©es

**Diagnostic:**
```bash
redis-cli
INFO memory
# maxmemory: 256mb
# used_memory: 255mb ‚ö†Ô∏è

# Voir les cl√©s qui prennent de la place
MEMORY USAGE celery-task-result:abc-123
```

**Solutions:**
```bash
# Augmenter m√©moire Redis
# Dans redis.conf
maxmemory 1gb

# Ou purger les anciens r√©sultats
redis-cli
KEYS celery-task-result:* | xargs DEL

# Configurer TTL automatique (Celery)
celery.conf.result_expires = 3600  # 1 heure
```

---

## 9. Best Practices

### Production Checklist

‚úÖ **1. Un seul Beat**
```bash
# Process manager (Supervisor, systemd)
[program:celery-beat]
command=celery -A app.workers.celery_app beat
numprocs=1  # UN SEUL
```

‚úÖ **2. Workers par queue**
```bash
# Worker d√©di√© par type de t√¢che
celery -A ... worker -Q ingest -n ingest@%h --autoscale=10,3
celery -A ... worker -Q scheduler -n scheduler@%h --autoscale=5,2
celery -A ... worker -Q comments -n comments@%h --autoscale=3,1
```

‚úÖ **3. Monitoring**
- Flower (UI web)
- Sentry (erreurs)
- Prometheus + Grafana (m√©triques)

‚úÖ **4. Retry Strategy**
```python
@celery.task(
    bind=True,
    max_retries=3,
    default_retry_delay=60,  # 1 min entre retries
)
def my_task(self, ...):
    try:
        # Code
    except Exception as e:
        raise self.retry(exc=e)
```

‚úÖ **5. Redis Persistence**
```bash
# redis.conf
save 900 1     # Snapshot toutes les 15 min si 1 key modifi√©e
save 300 10    # Snapshot toutes les 5 min si 10 keys modifi√©es
save 60 10000  # Snapshot toutes les 1 min si 10k keys modifi√©es
```

---

## 10. Comparaison Finale

### Avant Celery (Na√Øf)

```python
# FastAPI bloque pendant le traitement
@app.post("/webhook")
async def webhook(data):
    message = save_message(data)  # 100ms

    # ‚è∞ 10 secondes d'attente
    response = await process_with_ai(message)  # 10s

    await send_response(response)  # 500ms

    return {"status": "ok"}  # ‚ö†Ô∏è Timeout Meta (> 5s)
```

**Probl√®mes:**
- ‚ùå Timeout Meta
- ‚ùå API bloqu√©e
- ‚ùå Si crash, t√¢che perdue
- ‚ùå Pas de retry
- ‚ùå Pas de scalabilit√©

---

### Avec Celery (Production)

```python
# FastAPI r√©pond imm√©diatement
@app.post("/webhook")
async def webhook(data):
    message = save_message(data)  # 100ms

    # Envoie √† Celery (10ms)
    process_message.delay(message.id)

    return {"status": "ok"}  # ‚úÖ < 200ms

# Worker traite en arri√®re-plan
@celery.task(bind=True, max_retries=3)
def process_message(self, message_id):
    try:
        message = get_message(message_id)
        response = process_with_ai(message)  # 10s, pas grave
        send_response(response)
    except Exception as e:
        raise self.retry(exc=e, countdown=60)
```

**Avantages:**
- ‚úÖ FastAPI r√©pond < 200ms
- ‚úÖ Pas de timeout
- ‚úÖ Si crash, task reste dans Redis
- ‚úÖ Retry automatique
- ‚úÖ Scalable (multiple workers)

---

## R√©sum√© en 1 Image

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CELERY + REDIS                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üè≠ REDIS (La Poste)
‚îú‚îÄ üì¨ Queue "ingest"     ‚Üí [Task1, Task2, Task3]
‚îú‚îÄ üì¨ Queue "scheduler"  ‚Üí [Task4, Task5]
‚îî‚îÄ üì¨ Queue "comments"   ‚Üí [Task6]

üë∑ CELERY WORKER (Les Facteurs)
‚îú‚îÄ Worker 1 ‚Üí √âcoute "ingest"     ‚Üí Prend Task1 ‚Üí Ex√©cute
‚îú‚îÄ Worker 2 ‚Üí √âcoute "scheduler"  ‚Üí Prend Task4 ‚Üí Ex√©cute
‚îî‚îÄ Worker 3 ‚Üí √âcoute "comments"   ‚Üí Prend Task6 ‚Üí Ex√©cute

‚è∞ CELERY BEAT (L'Horloge)
‚îú‚îÄ Toutes les 0.5s  ‚Üí Envoie scan_redis_batches ‚Üí Queue "ingest"
‚îú‚îÄ Toutes les 5 min ‚Üí Envoie poll_comments      ‚Üí Queue "comments"
‚îî‚îÄ Toutes les 1 min ‚Üí Envoie enqueue_posts      ‚Üí Queue "scheduler"

üì± FASTAPI (Le Client)
‚îî‚îÄ Webhook arrive ‚Üí Envoie task ‚Üí Queue "ingest" ‚Üí R√©pond "OK"
```

---

## Commandes de D√©marrage (Copier-Coller)

**Production:**
```bash
# Terminal 1: FastAPI
cd backend && uvicorn app.main:app --host 0.0.0.0 --port 8000

# Terminal 2: Worker Ingest
celery -A app.workers.celery_app worker -l info -Q ingest -n ingest@%h --autoscale=10,3

# Terminal 3: Worker Scheduler
celery -A app.workers.celery_app worker -l info -Q scheduler -n scheduler@%h --autoscale=5,2

# Terminal 4: Worker Comments
celery -A app.workers.celery_app worker -l info -Q comments -n comments@%h --autoscale=3,1

# Terminal 5: Beat (UN SEUL) ‚ö†Ô∏è
celery -A app.workers.celery_app beat -l info

# Terminal 6 (optionnel): Monitoring
celery -A app.workers.celery_app flower --port=5555
```

**Dev:**
```bash
# Terminal 1: FastAPI
uvicorn app.main:app --reload

# Terminal 2: All-in-one
celery -A app.workers.celery_app worker --beat -l info -Q ingest,scheduler,comments
```

---

## Conclusion

**Redis:**
- üì¨ File d'attente de messages (broker)
- üíæ Stockage des r√©sultats (backend)
- ‚ö° Ultra-rapide (en m√©moire)

**Celery Worker:**
- üë∑ Ex√©cute les t√¢ches
- üîÑ Peut y en avoir plusieurs
- üìä Scalable horizontalement

**Celery Beat:**
- ‚è∞ Planifie les t√¢ches p√©riodiques
- üìÖ Comme un cron distribu√©
- ‚ö†Ô∏è **UN SEUL** par syst√®me

**Sans Beat ‚Üí T√¢ches p√©riodiques ne s'ex√©cutent PAS !**

---

*Derni√®re mise √† jour: 2025-10-20*
*Questions ? Ping @claude*
