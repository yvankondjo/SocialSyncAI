"""
Unified Search Service - Combines FAQ and Document Search with Parallel Execution

This service orchestrates parallel searches across FAQ and knowledge documents
using synchronous Supabase client with thread-based parallelism.
"""

import time
import logging
from typing import List, Literal, Optional
from pydantic import BaseModel
from concurrent.futures import ThreadPoolExecutor, as_completed

from app.services.find_answers import FindAnswers, Answer, ReferencedAnswer
from app.services.retriever import Retriever

logger = logging.getLogger(__name__)


class QueryItem(BaseModel):
    """
    A search query with language specification.
    Typically generated by the LLM based on doc_lang configuration.
    """

    query: str
    lang: Literal["french", "english", "spanish"] = "french"


class SearchMetadata(BaseModel):
    """Metadata about the search execution"""

    faq_latency: float
    docs_latency: float
    total_latency: float
    strategy_used: str
    faq_count: int
    docs_count: int


class UnifiedSearchResult(BaseModel):
    """
    Unified result from parallel FAQ + document search
    """

    answer_content: Optional[str] = None
    answer_grade: Literal["full", "partial", "no-answer"]
    faq_references: List[dict] = []
    doc_chunks: List[str] = []
    metadata: SearchMetadata


class UnifiedSearchService:
    """
    Service that orchestrates parallel search across FAQ and knowledge documents.

    Uses synchronous Supabase client with thread-based parallelism.
    """

    def __init__(self, user_id: str, model_name: str = "x-ai/grok-4-fast"):
        """
        Initialize unified search service.

        Args:
            user_id: User ID for filtering results
            model_name: LLM model to use for FAQ reasoning
        """
        self.user_id = user_id
        self.find_answers = FindAnswers(user_id, model_name)
        self.retriever = Retriever(user_id)

    def search(self, question: str, queries: List[QueryItem]) -> UnifiedSearchResult:
        """
        Execute parallel search across FAQ and documents.

        This is the main entry point that:
        1. Launches FAQ search and document search in parallel using threads
        2. Waits for both to complete
        3. Intelligently merges results based on FAQ grade
        4. Returns unified result with metadata

        Args:
            question: Original user question (for FAQ search)
            queries: List of search queries with languages (for document search)

        Returns:
            UnifiedSearchResult with answer, grade, references, and metadata
        """
        start_time = time.time()

        logger.info(f"ðŸ” Starting unified search for question: '{question}'")
        logger.info(f"ðŸ“ Document queries: {[q.query for q in queries]}")

        with ThreadPoolExecutor(max_workers=2) as executor:
            faq_future = executor.submit(self._search_faq_with_timing, question)
            docs_future = executor.submit(self._search_docs_with_timing, queries)

            (faq_result, faq_time) = faq_future.result()
            (doc_chunks, docs_time) = docs_future.result()

        logger.info(
            f"âœ… FAQ search completed in {faq_time:.2f}s (grade: {faq_result.grade})"
        )
        logger.info(
            f"âœ… Docs search completed in {docs_time:.2f}s ({len(doc_chunks)} chunks found)"
        )

        total_time = time.time() - start_time

        metadata = SearchMetadata(
            faq_latency=faq_time,
            docs_latency=docs_time,
            total_latency=total_time,
            strategy_used=self._get_strategy_name(faq_result.grade),
            faq_count=len(faq_result.references) if faq_result.references else 0,
            docs_count=len(doc_chunks),
        )

        final_result = self._merge_results(faq_result, doc_chunks, metadata)

        logger.info(
            f"ðŸŽ¯ Unified search completed in {total_time:.2f}s "
            f"(strategy: {final_result.metadata.strategy_used}, "
            f"grade: {final_result.answer_grade})"
        )

        return final_result

    def _search_faq_with_timing(self, question: str) -> tuple[Answer, float]:
        """
        Execute FAQ search with timing measurement.

        Args:
            question: User question

        Returns:
            Tuple of (Answer, latency_in_seconds)
        """
        start = time.time()
        try:
            result = self.find_answers.find_answers(question)
            latency = time.time() - start
            return result, latency
        except Exception as e:
            latency = time.time() - start
            logger.error(f"âŒ FAQ search failed after {latency:.2f}s: {str(e)}")
            return (
                Answer(
                    content=None,
                    grade="no-answer",
                    evaluation=f"FAQ search error: {str(e)}",
                    references=[],
                    extracted_entities=[],
                ),
                latency,
            )

    def _search_docs_with_timing(
        self, queries: List[QueryItem]
    ) -> tuple[List[str], float]:
        """
        Execute document search with timing measurement.

        Optimizations:
        1. Batch embedding generation (all queries in one API call)
        2. Parallel RPC calls for each query using threads

        Args:
            queries: List of search queries with languages

        Returns:
            Tuple of (list of document chunks, latency_in_seconds)
        """
        start = time.time()

        if not queries:
            logger.warning("âš ï¸  No queries provided for document search")
            return [], 0.0

        try:
            query_texts = [q.query for q in queries]
            embeddings = self.retriever.embed_texts(query_texts)

            logger.info(f"ðŸ”¢ Generated {len(embeddings)} embeddings in batch")

            all_chunks = []
            with ThreadPoolExecutor(max_workers=len(queries)) as executor:
                futures = {
                    executor.submit(self._search_single_query, q, emb): i
                    for i, (q, emb) in enumerate(zip(queries, embeddings))
                }

                for future in as_completed(futures):
                    i = futures[future]
                    try:
                        results = future.result()
                        all_chunks.extend([r["content"] for r in results])
                    except Exception as e:
                        logger.error(f"âŒ Query {i+1} failed: {str(e)}")

            latency = time.time() - start
            return all_chunks, latency

        except Exception as e:
            latency = time.time() - start
            logger.error(f"âŒ Document search failed after {latency:.2f}s: {str(e)}")
            return [], latency

    def _search_single_query(
        self, query: QueryItem, embedding: List[float]
    ) -> List[dict]:
        """
        Execute search for a single query with pre-computed embedding.

        Args:
            query: Query with language specification
            embedding: Pre-computed embedding vector

        Returns:
            List of search results with content and score
        """
        from app.db.session import get_db
        import re

        try:
            db = get_db()

            processed_query = " ".join(query.query.split())
            processed_query = re.sub(r"\s+", " | ", processed_query)

            response = db.rpc(
                "hybrid_knowledge_chunks_search_v2",
                {
                    "p_user_id": self.user_id,
                    "query_text": processed_query,
                    "query_embedding": embedding,
                    "query_lang": query.lang,
                    "match_count": 10,
                    "rrf_k": 10,
                },
            ).execute()

            return response.data if response.data else []

        except Exception as e:
            logger.error(f"âŒ Search failed for query '{query.query}': {str(e)}")
            raise

    def _merge_results(
        self, faq_result: Answer, doc_chunks: List[str], metadata: SearchMetadata
    ) -> UnifiedSearchResult:
        """
        Intelligently merge FAQ and document results based on FAQ grade.

        Strategy:
        - full: Use FAQ answer only (docs ignored but were calculated in parallel by the LLM)
        - partial: Enrich FAQ answer with top 3 doc chunks
        - no-answer: Use docs only (or escalate if also empty)

        Args:
            faq_result: Result from FAQ search
            doc_chunks: List of document chunk contents
            metadata: Search metadata with timing and strategy information

        Returns:
            UnifiedSearchResult with merged content
        """
        if faq_result.grade == "full":
            logger.info("âœ… Using FAQ answer (full match)")
            return UnifiedSearchResult(
                answer_content=faq_result.content,
                answer_grade="full",
                faq_references=[
                    ref.model_dump() for ref in (faq_result.references or [])
                ],
                doc_chunks=[],
                metadata=metadata,
            )

        elif faq_result.grade == "partial":
            logger.info("ðŸ“ Enriching partial FAQ answer with documents")

            if doc_chunks:
                enriched_content = (
                    f"{faq_result.content}\n\n"
                    f"**Additional information:**\n\n"
                    f"{doc_chunks}"
                )
            else:
                enriched_content = faq_result.content

            return UnifiedSearchResult(
                answer_content=enriched_content,
                answer_grade="partial",
                faq_references=[
                    ref.model_dump() for ref in (faq_result.references or [])
                ],
                doc_chunks=doc_chunks,
                metadata=metadata,
            )

        else:
            logger.info("ðŸ“š Using document chunks only (no FAQ match)")

            if doc_chunks:
                return UnifiedSearchResult(
                    answer_content=None,
                    answer_grade="partial",
                    faq_references=[],
                    doc_chunks=doc_chunks,
                    metadata=metadata,
                )
            else:
                logger.warning("âš ï¸  No results from FAQ or documents")
                return UnifiedSearchResult(
                    answer_content=None,
                    answer_grade="no-answer",
                    faq_references=[],
                    doc_chunks=[],
                    metadata=metadata,
                )

    def _get_strategy_name(self, faq_grade: str) -> str:
        """
        Get human-readable strategy name from FAQ grade.

        Args:
            faq_grade: FAQ answer grade (full/partial/no-answer)

        Returns:
            Strategy name string
        """
        mapping = {
            "full": "faq_only",
            "partial": "faq_enriched",
            "no-answer": "docs_only",
        }
        return mapping.get(faq_grade, "unknown")
