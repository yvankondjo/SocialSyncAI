# üîç Guide d'Int√©gration LangSmith - SocialSyncAI

## üéØ Pourquoi LangSmith ?

LangSmith est l'outil officiel de monitoring pour LangChain/LangGraph. Il offre :

- **Tracing complet** : Visualisation de chaque √©tape de tes agents RAG
- **M√©triques d√©taill√©es** : Latence, tokens, co√ªt par invocation
- **Monitoring des erreurs** : Stack traces et contexte complet
- **Optimisation** : A/B testing des prompts et mod√®les
- **Alertes** : Notifications sur les anomalies de performance

## üìã Installation et Configuration

### 1. Installation des d√©pendances

```bash
pip install langsmith langchain
```

### 2. Configuration environnement

```bash
# .env
LANGCHAIN_API_KEY=lsv2_pt_your_key_here
LANGCHAIN_PROJECT=socialsync-ai-prod
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_TRACING_V2=true

# Optionnel - pour les environnements
LANGCHAIN_ENV=production
```

### 3. Obtenir une cl√© API LangSmith

1. **Cr√©er un compte** : [smith.langchain.com](https://smith.langchain.com)
2. **Aller dans Settings** ‚Üí API Keys
3. **Cr√©er une cl√©** avec les permissions appropri√©es
4. **Copier la cl√©** dans ton `.env`

## üîß Int√©gration dans le Code

### 1. Configuration globale (optionnel)

```python
# app/__init__.py ou main.py
import os
from langsmith import Client

# Configuration automatique via variables d'environnement
os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
os.environ.setdefault("LANGCHAIN_PROJECT", "socialsync-ai-prod")

# Client pour les op√©rations avanc√©es
langsmith_client = Client()
```

### 2. Monitoring automatique

**LangSmith s'int√®gre automatiquement** avec ton agent RAG existant :

```python
# app/services/rag_agent.py - Pas de modification n√©cessaire !
from langchain_openai import ChatOpenAI

# LangSmith trace automatiquement :
# - Toutes les invocations LLM
# - Les appels aux tools (search_files)
# - Les erreurs et timeouts
# - Les m√©triques de tokens

llm = ChatOpenAI(
    api_key=os.getenv('OPENROUTER_API_KEY'),
    base_url="https://openrouter.ai/api/v1",
    model="gpt-4o-mini"
)
```

## üìä M√©triques Collect√©es

### M√©triques de base
- **Dur√©e totale** d'ex√©cution par conversation
- **Tokens input/output** par invocation
- **Co√ªt estim√©** par requ√™te
- **Taux de succ√®s** des recherches

### M√©triques avanc√©es
- **Latence par √©tape** : search ‚Üí LLM ‚Üí response
- **Utilisation des tools** : nombre d'appels search_files
- **Erreurs par type** : API, parsing, timeout
- **Mod√®les utilis√©s** : gpt-4o-mini, etc.

## üéõÔ∏è Dashboard LangSmith

### 1. Acc√®s au dashboard
- **URL** : [smith.langchain.com](https://smith.langchain.com)
- **Projet** : `socialsync-ai-prod`
- **Traces** : Visualisation des executions

### 2. M√©triques cl√©s √† surveiller

#### Performance
```
- P95 latence totale < 30s
- Taux de succ√®s > 95%
- Tokens moyens par requ√™te < 4000
```

#### Qualit√©
```
- Erreurs de parsing < 1%
- Timeouts < 2%
- Co√ªt moyen par conversation < 0.05‚Ç¨
```

#### Usage
```
- Requ√™tes par minute
- Utilisateurs actifs
- Mod√®les les plus utilis√©s
```

## üö® Alertes et Monitoring

### 1. Configuration des alertes

```python
# Exemple d'alerte sur les erreurs
from langsmith import Client

client = Client()

# R√©cup√©rer les runs √©chou√©s
failed_runs = client.list_runs(
    project_name="socialsync-ai-prod",
    filter="error is not null",
    limit=10
)

# Alert si > 5% d'erreurs
error_rate = len(failed_runs) / total_runs
if error_rate > 0.05:
    # Envoyer alerte (Slack, email, etc.)
    send_alert(f"High error rate: {error_rate*100".1f"}%")
```

### 2. Monitoring avec Prometheus/Grafana

```python
# Exporter les m√©triques
from prometheus_client import Counter, Histogram, Gauge

# Compteurs pour les m√©triques
CONVERSATIONS_PROCESSED = Counter(
    'conversations_processed_total',
    'Total conversations processed'
)

RESPONSE_TIME = Histogram(
    'conversation_response_time_seconds',
    'Time to process a conversation',
    buckets=[1, 5, 10, 30, 60, 120]
)

ERRORS = Counter(
    'conversation_errors_total',
    'Total errors by type',
    labelnames=['error_type']
)
```

## üîç Debugging avec LangSmith

### 1. Recherche de traces

```python
from langsmith import Client

client = Client()

# Trouver une conversation sp√©cifique
runs = client.list_runs(
    project_name="socialsync-ai-prod",
    filter=f'metadata.conversation_id = "{conversation_id}"'
)

# Analyser les d√©tails
for run in runs:
    print(f"Duration: {run.latency}")
    print(f"Tokens: {run.total_tokens}")
    print(f"Model: {run.model}")
    if run.error:
        print(f"Error: {run.error}")
```

### 2. Comparaison A/B

```python
# Comparer les performances entre mod√®les
comparison = client.evaluate(
    project_name="socialsync-ai-prod",
    experiment_name="model-comparison",
    runs=[
        {"model": "gpt-4o-mini", "run_id": "run_1"},
        {"model": "gpt-4o", "run_id": "run_2"}
    ]
)

print(f"gpt-4o-mini: {comparison['gpt-4o-mini']['avg_latency']}")
print(f"gpt-4o: {comparison['gpt-4o']['avg_latency']}")
```

## üìà Optimisation avec les donn√©es

### 1. Analyse des co√ªts

```python
# Calculer le co√ªt par utilisateur
costs = client.list_runs(
    project_name="socialsync-ai-prod",
    filter="status = 'completed'"
)

user_costs = {}
for run in costs:
    user_id = run.metadata.get('user_id')
    cost = run.total_cost or 0
    user_costs[user_id] = user_costs.get(user_id, 0) + cost

# Identifier les utilisateurs co√ªteux
high_cost_users = {k: v for k, v in user_costs.items() if v > 10}  # > 10‚Ç¨
```

### 2. Optimisation des prompts

```python
# A/B testing des prompts
experiments = client.list_experiments(
    project_name="socialsync-ai-prod"
)

for exp in experiments:
    print(f"Prompt A: {exp['prompt_a']['avg_tokens']}")
    print(f"Prompt B: {exp['prompt_b']['avg_tokens']}")
```

## üéØ Recommandations pour Production

### 1. Configuration recommand√©e

```python
# Pour la production
os.environ.update({
    "LANGCHAIN_TRACING_V2": "true",
    "LANGCHAIN_PROJECT": "socialsync-ai-prod",
    "LANGCHAIN_ENV": "production",
    "LANGCHAIN_TRACING_SAMPLING_RATE": "0.1",  # 10% des traces
})

# Pour le d√©veloppement
os.environ.update({
    "LANGCHAIN_TRACING_V2": "true",
    "LANGCHAIN_PROJECT": "socialsync-ai-dev",
    "LANGCHAIN_ENV": "development",
    "LANGCHAIN_TRACING_SAMPLING_RATE": "1.0",  # 100% des traces
})
```

### 2. Int√©gration avec tes m√©triques existantes

```python
# Compl√©ment au BatchScanner
class EnhancedBatchScanner(BatchScanner):
    def __init__(self):
        super().__init__()
        self.langsmith_client = Client()

    async def log_to_langsmith(self, conversation_data):
        """Logger dans LangSmith pour corr√©lation"""
        run = self.langsmith_client.create_run(
            name=f"conversation_{conversation_data['conversation_id']}",
            run_type="chain",
            inputs={"user_message": conversation_data["message"]},
            metadata={
                "platform": conversation_data["platform"],
                "user_id": conversation_data["user_id"],
                "conversation_id": conversation_data["conversation_id"]
            }
        )

        # Ajouter les r√©sultats
        self.langsmith_client.update_run(
            run.id,
            outputs={"response": conversation_data["response"]},
            end_time=datetime.now()
        )
```

## üöÄ Avantages pour SocialSyncAI

1. **Monitoring complet** : De WhatsApp webhook √† la r√©ponse finale
2. **Optimisation RAG** : Am√©liorer la pertinence des r√©ponses
3. **R√©duction des co√ªts** : Identifier les requ√™tes inefficaces
4. **D√©bugging rapide** : Trouver les probl√®mes en quelques clics
5. **SLA monitoring** : S'assurer du respect des temps de r√©ponse

## üí° Prochaines √©tapes

1. **Tester l'int√©gration** sur quelques conversations
2. **Configurer les alertes** sur les m√©triques critiques
3. **Optimiser les prompts** bas√©s sur les donn√©es
4. **Int√©grer avec Grafana** pour un dashboard unifi√©
5. **Configurer la r√©tention** des traces (30 jours recommand√©)

**LangSmith transformera ton monitoring d'un syst√®me basique √† un observatoire complet de tes agents RAG !** üéâ
